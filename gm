#!/Users/jeffrey.heinen/projects/shadowdark-gm/.venv/bin/python

"""
Shadowdark GM CLI Tool - New Multi-Stage Audio Processing Pipeline
"""

import argparse
import sys
import os
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv

# Import new agents
from core.agents.audio_splitter import AudioSplitter
from core.agents.transcript_generator import TranscriptGenerator  
from core.agents.transcript_merger import TranscriptMerger

load_dotenv()

def main():
    parser = argparse.ArgumentParser(
        prog='gm',
        description='Shadowdark GM Assistant CLI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # New Multi-Stage Audio Processing Pipeline
  gm audio split "large_file.m4a" --output-dir segments/
  gm audio transcribe "segment.m4a"
  gm transcript merge merged.md transcript1.md transcript2.md
  
  # Session Processing  
  gm session summarize transcript.md --out final_notes.md
  gm session summarize audio.wav --campaign 1 --use-rag
        '''
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Audio processing commands
    audio_parser = subparsers.add_parser('audio', help='Audio processing commands')
    audio_subparsers = audio_parser.add_subparsers(dest='audio_cmd')
    
    # Audio split command
    split_parser = audio_subparsers.add_parser('split', help='Split large audio files')
    split_parser.add_argument('input', help='Input audio file')
    split_parser.add_argument('--output-dir', default='segments', help='Output directory for segments')
    split_parser.add_argument('--segment-duration', type=int, help='Segment duration in seconds')
    
    # Audio transcribe command  
    transcribe_parser = audio_subparsers.add_parser('transcribe', help='Generate diarized transcript from audio')
    transcribe_parser.add_argument('input', help='Input audio file')
    transcribe_parser.add_argument('--output', help='Output transcript file')
    transcribe_parser.add_argument('--quality', choices=['fast', 'balanced', 'precise'], default='balanced',
                                 help='Diarization quality: fast (more segments), balanced (default), precise (fewer segments)')
    transcribe_parser.add_argument('--no-diarization', action='store_true',
                                 help='Skip speaker diarization, generate transcript with timestamps only')
    transcribe_parser.add_argument('--manual-segments', type=int, default=None,
                                 help='Split transcript into N manual segments for easier speaker assignment')
    transcribe_parser.add_argument('--time-segments', type=int, default=None,
                                 help='Create time-based segments every N minutes for speaker assignment')
    
    # Transcript processing commands
    transcript_parser = subparsers.add_parser('transcript', help='Transcript processing commands')
    transcript_subparsers = transcript_parser.add_subparsers(dest='transcript_cmd')
    
    # Transcript merge command
    merge_parser = transcript_subparsers.add_parser('merge', help='Merge multiple transcript files')
    merge_parser.add_argument('output', help='Output merged transcript file')
    merge_parser.add_argument('transcripts', nargs='+', help='Input transcript files to merge')
    
    # Session processing commands
    session_parser = subparsers.add_parser('session', help='Session processing commands')
    session_subparsers = session_parser.add_subparsers(dest='session_cmd')
    
    summarize_parser = session_subparsers.add_parser('summarize', help='Generate session notes')
    summarize_parser.add_argument('input', help='Input file (transcript, audio, etc.)')
    summarize_parser.add_argument('--out', help='Output file or "notion" for Notion sync')
    summarize_parser.add_argument('--campaign', type=int, help='Campaign ID')
    summarize_parser.add_argument('--use-rag', action='store_true', help='Use RAG for additional context')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    print(f"‚úÖ CLI is working! Command: {args.command}")
    if hasattr(args, 'audio_cmd') and args.audio_cmd:
        print(f"   Audio subcommand: {args.audio_cmd}")
    if hasattr(args, 'transcript_cmd') and args.transcript_cmd:
        print(f"   Transcript subcommand: {args.transcript_cmd}")
    if hasattr(args, 'session_cmd') and args.session_cmd:
        print(f"   Session subcommand: {args.session_cmd}")
    print(f"   Args: {vars(args)}")
    
    # Execute the actual commands
    if args.command == 'audio':
        if args.audio_cmd == 'split':
            cmd_audio_split(args)
        elif args.audio_cmd == 'transcribe':
            cmd_audio_transcribe(args)
    elif args.command == 'transcript':
        if args.transcript_cmd == 'merge':
            cmd_transcript_merge(args)
    elif args.command == 'session':
        if args.session_cmd == 'summarize':
            cmd_session_summarize(args)

def cmd_audio_split(args):
    """Split large audio files into segments"""
    print(f"\nüî™ Splitting audio file: {args.input}")
    
    if not os.path.exists(args.input):
        print(f"‚ùå Input file not found: {args.input}")
        return
    
    try:
        splitter = AudioSplitter()
        
        # Check if splitting is needed
        input_path = Path(args.input)
        if not splitter.should_split(input_path):
            print("‚úÖ File is small enough - no splitting needed!")
            return
            
        # Create output directory
        os.makedirs(args.output_dir, exist_ok=True)
        print(f"üìÅ Output directory: {args.output_dir}")
        
        # Split the file
        segments = splitter.split_audio(
            audio_path=args.input,
            output_dir=args.output_dir
        )
        
        print(f"\n‚úÖ Successfully split into {len(segments)} segments:")
        for i, segment_path in enumerate(segments, 1):
            file_size = os.path.getsize(segment_path) / (1024 * 1024)  # MB
            print(f"   {i}. {segment_path} ({file_size:.1f} MB)")
            
        print(f"\nNext steps:")
        print(f"1. Transcribe each segment:")
        for segment_path in segments:
            print(f"   ./gm audio transcribe \"{segment_path}\"")
        print(f"\n2. Merge transcripts:")
        transcript_pattern = f"{args.output_dir}/*_transcript.md"
        output_name = Path(args.input).stem + "_merged_transcript.md"
        print(f"   ./gm transcript merge \"{output_name}\" {transcript_pattern}")
        
    except Exception as e:
        print(f"‚ùå Error splitting audio: {e}")

def cmd_audio_transcribe(args):
    """Transcribe audio file to diarized transcript"""
    print(f"\nüéôÔ∏è Transcribing audio file: {args.input}")
    
    if not os.path.exists(args.input):
        print(f"‚ùå Input file not found: {args.input}")
        return
    
    try:
        # Check for HuggingFace token
        huggingface_token = os.getenv("HUGGINGFACE_TOKEN")
        if not huggingface_token:
            print("‚ö†Ô∏è  Warning: No HUGGINGFACE_TOKEN found.")
            print("   You may need to set this environment variable for speaker diarization.")
        
        generator = TranscriptGenerator(huggingface_token=huggingface_token)
        
        # Generate output filename if not provided
        if not args.output:
            input_path = Path(args.input)
            args.output = f"{input_path.stem}_transcript.md"
        
        print("üîÑ Processing audio (this may take several minutes)...")
        
        # Check for no-diarization mode
        if args.no_diarization or args.manual_segments or args.time_segments:
            # Generate simple transcript without diarization or with manual segmentation
            openai_api_key = os.getenv("OPENAI_API_KEY")
            transcript_gen = TranscriptGenerator(huggingface_token=huggingface_token, openai_api_key=openai_api_key)
            # The method saves the file internally and returns the path
            transcript_path = transcript_gen.generate_simple_transcript(
                args.input, 
                args.output, 
                args.manual_segments, 
                args.time_segments
            )
        else:
            # Generate transcript (this already saves the file internally)
            transcript_path = generator.generate_transcript(
                audio_path=args.input,
                output_path=args.output,
                quality=args.quality
            )
        
        print(f"‚úÖ Transcript saved to: {args.output}")
        print("\n‚ö†Ô∏è  CRITICAL NEXT STEPS:")
        print("1. üéØ MUST FIX SPEAKER LABELS - Each segment gets different Speaker IDs!")
        print("   - Replace Speaker_1, Speaker_2 with actual names (GM, Alice, Bob)")
        print("   - Same person = same name across ALL segments")
        print("2. Review transcript accuracy and fix errors")
        print("3. Add context like [dice roll], [laughter], [pause]")
        print(f"4. Only AFTER fixing speakers: merge transcripts or generate notes")
        
    except Exception as e:
        print(f"‚ùå Error generating transcript: {e}")

def cmd_transcript_merge(args):
    """Merge multiple transcript files"""
    print(f"\nüîó Merging transcripts into: {args.output}")
    
    # Check input files
    missing_files = [f for f in args.transcripts if not os.path.exists(f)]
    if missing_files:
        print(f"‚ùå Missing files: {missing_files}")
        return
    
    try:
        merger = TranscriptMerger()
        
        print(f"üìÅ Input files:")
        for i, transcript_path in enumerate(args.transcripts, 1):
            file_size = os.path.getsize(transcript_path) / 1024  # KB
            print(f"   {i}. {transcript_path} ({file_size:.1f} KB)")
        
        print("üîÑ Merging transcripts...")
        
        # Merge transcripts
        merged_content = merger.merge_transcripts(args.transcripts)
        
        # Save merged transcript
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(merged_content)
        
        output_size = os.path.getsize(args.output) / 1024  # KB
        print(f"‚úÖ Merged transcript saved to: {args.output} ({output_size:.1f} KB)")
        
        print("\n‚úÖ Merge Complete - Final Quality Check:")
        print(f"1. üîç Review the merged transcript: {args.output}")
        print("2. ‚úèÔ∏è  Verify speaker names are consistent throughout")
        print("3. üéØ Final accuracy check and context additions")
        print("4. üìã Generate session notes:")
        session_notes_name = Path(args.output).stem.replace("_transcript", "_session_notes") + ".md"
        print(f"   ./gm session summarize \"{args.output}\" --out \"{session_notes_name}\"")
        
    except Exception as e:
        print(f"‚ùå Error merging transcripts: {e}")

def cmd_session_summarize(args):
    """Generate session notes from transcript"""
    print(f"\nüìã Generating session notes from: {args.input}")
    
    if not os.path.exists(args.input):
        print(f"‚ùå Input file not found: {args.input}")
        return
        
    # For now, provide instructions for manual processing
    print("üöß Session note generation from transcript will use the existing pipeline.")
    print("\nTo generate session notes:")
    print(f"1. Ensure {args.input} is a clean, reviewed transcript")
    print("2. Use the original session command (without audio processing):")
    
    if args.out:
        print(f"   ./gm session summarize \"{args.input}\" --out \"{args.out}\"")
    else:
        output_name = Path(args.input).stem.replace("_transcript", "_session_notes") + ".md"
        print(f"   ./gm session summarize \"{args.input}\" --out \"{output_name}\"")
    
    if args.use_rag:
        print("   Add --use-rag for additional context")
    if args.campaign:
        print(f"   Add --campaign {args.campaign} for campaign tracking")

if __name__ == '__main__':
    main()