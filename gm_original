#!/Users/jeffrey.heinen/projects/shadowdark-gm/.venv/bin/python

"""
Shadowdark GM CLI Tool

Command-line interface for the Shadowdark GM Assistant.
Usage:
    gm session summarize input.md --out notion
    gm session summarize transcript.txt --campaign 1 --use-rag
    gm session summarize audio.wav --campaign 1 --out notion
    gm rag ingest rules.pdf --doctype rule
    gm rag query "How do spells work?"
"""

import argparse
import sys
import os
from pathlib import Path
from typing import Optional

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from sqlmodel import create_engine, Session
from dotenv import load_dotenv

from core.agents.session_scribe import summarize_text, summarize_audio
from core.agents.rag_librarian import ingest_text, ingest_file, search
from core.agents.gm_chat import GMChatAgent
from core.data.vector_store import query
from core.data.models import SQLModel, Document
from core.integrations.notion_sync import NotionSync

load_dotenv()

# Database setup - lazy initialization
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+psycopg://postgres:postgres@localhost:5432/shadowdark")
engine = None

def get_db_engine():
    """Get database engine with lazy initialization"""
    global engine
    if engine is None:
        try:
            engine = create_engine(DATABASE_URL, pool_pre_ping=True, connect_args={"connect_timeout": 5})
            # Test connection briefly
            with engine.connect() as conn:
                pass
            print("âœ… Database connection established")
        except Exception as e:
            print(f"âš ï¸  Database connection failed: {e}")
            print("Database-dependent features will be unavailable")
            engine = False  # Mark as failed
    return engine if engine is not False else None

def read_file_content(file_path: str) -> str:
    """Read content from a file"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        return ""

def write_file_content(file_path: str, content: str):
    """Write content to a file"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… Output written to {file_path}")
    except Exception as e:
        print(f"âŒ Error writing file {file_path}: {e}")

def handle_session_output(args, notes):
    """Handle session output to various destinations"""
    if args.out == "stdout":
        print("\n" + "="*50)
        print(notes)
        print("="*50)
    elif args.out == "notion":
        # Sync to Notion
        print("ğŸ“ Syncing to Notion...")
        try:
            notion = NotionSync()
            
            # Test connection first
            if not notion.test_connection():
                print("âŒ Failed to connect to Notion. Check your NOTION_TOKEN.")
                print("   Saving to file instead...")
                write_file_content("session_notes.md", notes)
                return
            
            # Create the page
            page_url = notion.create_session_page(
                title=f"Session Notes - {Path(args.input).stem}",
                content=notes,
                properties={
                    "Play Group": {"select": {"name": getattr(args, 'play_group', 'Online')}}
                }
            )
            
            if page_url:
                print(f"âœ… Session notes created in Notion: {page_url}")
            else:
                print("âŒ Failed to create Notion page. Saving to file instead...")
                write_file_content("session_notes.md", notes)
            
        except Exception as e:
            print(f"âŒ Error syncing to Notion: {e}")
            print("   Saving to file instead...")
            write_file_content("session_notes.md", notes)
    else:
        # Save to file
        write_file_content(args.out, notes)
    
    print("âœ… Session summarization completed!")

def cmd_session_summarize(args):
    """Handle session summarize command"""
    if not os.path.exists(args.input):
        print(f"âŒ Input file not found: {args.input}")
        return
    
    # Check if input is an audio file
    audio_extensions = {'.wav', '.mp3', '.m4a', '.flac', '.ogg'}
    input_path = Path(args.input)
    is_audio = input_path.suffix.lower() in audio_extensions
    
    if is_audio:
        print(f"ğŸ™ï¸  Processing audio file: {args.input}")
        return cmd_session_audio_summarize(args)
    else:
        print(f"ğŸ“ Summarizing session from text file: {args.input}")
        
        # Read input file
        transcript = read_file_content(args.input)
        if not transcript.strip():
            print("âŒ Input file is empty")
            return
        
        # Get RAG context if requested
        context_chunks = []
        if args.use_rag:
            print("ğŸ” Gathering relevant context from knowledge base...")
            with Session(engine) as sess:
                # Use first few lines of transcript as search query
                search_query = transcript[:500]
                chunks = search(sess, search_query, k=3)
                context_chunks = [chunk.text for chunk in chunks]
                print(f"   Found {len(context_chunks)} relevant chunks")
        
        # Generate session notes
        print("ğŸ¤– Generating session notes...")
        try:
            with Session(engine) as sess:
                notes = summarize_text(
                    transcript, 
                    campaign_id=args.campaign,
                    context_chunks=context_chunks if context_chunks else None,
                    db_session=sess if args.save_to_db else None,
                    use_mock=not bool(os.getenv("OPENAI_API_KEY", "").startswith("sk-"))
                )
            
            # Handle output
            handle_session_output(args, notes)
            
        except Exception as e:
            print(f"âŒ Error generating session notes: {e}")

def cmd_session_audio_summarize(args):
    """Handle audio session summarize command"""
    print(f"ğŸ™ï¸  Processing audio session: {args.input}")
    
    # Get RAG context if requested
    context_chunks = []
    if args.use_rag:
        print("ğŸ” Gathering relevant context from knowledge base...")
        with Session(engine) as sess:
            # Use audio filename as search query for initial context
            search_query = f"session audio recording {Path(args.input).stem}"
            chunks = search(sess, search_query, k=3)
            context_chunks = [chunk.text for chunk in chunks]
            print(f"   Found {len(context_chunks)} relevant chunks")
    
    # Generate session notes from audio
    print("ğŸ¤– Processing audio and generating session notes...")
    try:
        huggingface_token = os.getenv("HUGGINGFACE_TOKEN")
        if not huggingface_token:
            print("âš ï¸  No HUGGINGFACE_TOKEN found. You may need to set this to access diarization models.")
        
        with Session(engine) as sess:
            notes = summarize_audio(
                audio_path=args.input,
                campaign_id=args.campaign,
                context_chunks=context_chunks if context_chunks else None,
                db_session=sess if args.save_to_db else None,
                huggingface_token=huggingface_token,
                use_mock=not bool(os.getenv("OPENAI_API_KEY", "").startswith("sk-")),
                fast_mode=getattr(args, 'fast', False)
            )
        
        # Handle output (same as text processing)
        handle_session_output(args, notes)
        
    except Exception as e:
        print(f"âŒ Error processing audio: {e}")
        if "gated repo" in str(e).lower() or "access" in str(e).lower():
            print("\nğŸ’¡ To enable audio processing:")
            print("1. Visit: https://huggingface.co/pyannote/speaker-diarization-community-1")
            print("2. Click 'Agree and access repository'")
            print("3. Create a token at: https://huggingface.co/settings/tokens")
            print("4. Set HUGGINGFACE_TOKEN environment variable")

def cmd_rag_ingest(args):
    """Handle RAG ingest command"""
    if not os.path.exists(args.file):
        print(f"âŒ File not found: {args.file}")
        return
    
    print(f"ğŸ“š Ingesting document: {args.file}")
    
    try:
        with Session(engine) as sess:
            doc_id = ingest_file(
                sess, 
                args.file, 
                title=args.title,
                doctype=args.doctype
            )
            print(f"âœ… Document ingested successfully with ID: {doc_id}")
    except Exception as e:
        print(f"âŒ Error ingesting document: {e}")

def cmd_rag_ingest_batch(args):
    """Handle RAG batch ingest command"""
    import os
    import glob
    from pathlib import Path
    
    directory = Path(args.directory)
    if not directory.exists():
        print(f"âŒ Directory not found: {directory}")
        return
    
    if not directory.is_dir():
        print(f"âŒ Path is not a directory: {directory}")
        return
    
    # Parse extensions
    extensions = [ext.strip() for ext in args.extensions.split(',')]
    
    # Find files to process
    files_to_process = []
    for ext in extensions:
        if args.recursive:
            pattern = f"**/*.{ext}"
        else:
            pattern = f"*.{ext}"
        
        files_to_process.extend(directory.glob(pattern))
    
    if not files_to_process:
        print(f"âŒ No files found with extensions: {', '.join(extensions)}")
        return
    
    print(f"ğŸ“š Found {len(files_to_process)} files to ingest from {directory}")
    print(f"   Extensions: {', '.join(extensions)}")
    print(f"   Recursive: {'Yes' if args.recursive else 'No'}")
    
    if args.doctype:
        print(f"   Document type: {args.doctype}")
    else:
        print("   Document type: Auto-detect")
    
    print("\n" + "=" * 50)
    
    success_count = 0
    error_count = 0
    
    with Session(engine) as sess:
        for file_path in files_to_process:
            try:
                print(f"ğŸ“„ Processing: {file_path.name}")
                
                doc_id = ingest_file(
                    sess,
                    file_path,
                    title=None,  # Use filename
                    doctype=args.doctype  # Will auto-detect if None
                )
                
                print(f"   âœ… Success (ID: {doc_id})")
                success_count += 1
                
            except Exception as e:
                print(f"   âŒ Error: {e}")
                error_count += 1
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š Batch ingestion complete:")
    print(f"   âœ… Successful: {success_count}")
    print(f"   âŒ Errors: {error_count}")
    print(f"   ğŸ“š Total processed: {len(files_to_process)}")
    
    if error_count > 0:
        print(f"\nâš ï¸  {error_count} files failed to process. Check error messages above.")

def cmd_chat(args):
    """Handle chat command - interactive GM Assistant"""
    print("ğŸ° Shadowdark GM Assistant Chat")
    print("=" * 40)
    print("Ask me anything about Shadowdark rules, monsters, spells, or GM advice!")
    print("Type 'quit', 'exit', or 'bye' to end the conversation.")
    print("Type 'reset' to clear conversation history.")
    print("=" * 40)
    
    try:
        with Session(engine) as sess:
            chat_agent = GMChatAgent(sess)
            
            # Handle reset flag
            if args.reset:
                chat_agent.reset_conversation()
                print("ğŸ”„ Conversation history reset.")
            
            # Handle single message mode
            if args.message:
                user_message = " ".join(args.message)
                print(f"\nğŸ‘¤ **You:** {user_message}")
                response = chat_agent.chat(user_message)
                print(f"\nğŸ§™â€â™‚ï¸ **GM Assistant:** {response}")
                return
            
            # Interactive chat mode
            print(f"\n{chat_agent.get_conversation_summary()}")
            print("\nğŸ’¬ **Chat started** - How can I help you today?\n")
            
            while True:
                try:
                    user_input = input("ğŸ‘¤ You: ").strip()
                    
                    if not user_input:
                        continue
                    
                    # Check for exit commands
                    if user_input.lower() in ['quit', 'exit', 'bye', 'goodbye']:
                        print("\nğŸ§™â€â™‚ï¸ **GM Assistant:** May your shadows be ever darker! Happy gaming! ğŸ²")
                        break
                    
                    # Check for reset command
                    if user_input.lower() == 'reset':
                        chat_agent.reset_conversation()
                        print("\nğŸ”„ **System:** Conversation history reset.\n")
                        continue
                    
                    # Get response from chat agent
                    print("\nğŸ§™â€â™‚ï¸ **GM Assistant:** ", end="", flush=True)
                    response = chat_agent.chat(user_input)
                    print(response)
                    
                    # Show sources if available
                    if hasattr(chat_agent.conversation, 'messages') and chat_agent.conversation.messages:
                        last_msg = chat_agent.conversation.messages[-1]
                        if last_msg.sources:
                            print(f"\nğŸ“š **Sources:** {', '.join(last_msg.sources)}")
                    
                    print()  # Empty line for readability
                    
                except KeyboardInterrupt:
                    print("\n\nğŸ§™â€â™‚ï¸ **GM Assistant:** Until next time, brave GM! ğŸ°")
                    break
                except EOFError:
                    print("\n\nğŸ§™â€â™‚ï¸ **GM Assistant:** Farewell! ğŸ‘‹")
                    break
                
    except Exception as e:
        print(f"âŒ Error starting chat: {e}")

def _preprocess_query(query_text: str):
    """
    Preprocess natural language queries to extract key terms and infer intent
    
    Args:
        query_text: Raw user query
        
    Returns:
        tuple: (processed_query, suggested_chunk_types)
    """
    import re
    
    query_lower = query_text.lower()
    
    # Extract creature names and key terms
    creature_patterns = [
        r'(?:stats?|statistics|stat block)\s+(?:for|of)\s+(?:a\s+)?(.+?)(?:\s*$|[.!?])',
        r'(?:give me|show me|find|get)\s+(?:the\s+)?(?:stats?|statistics)\s+(?:for|of)\s+(?:a\s+)?(.+?)(?:\s*$|[.!?])',
        r'(.+?)\s+(?:stats?|statistics|stat block)',
        r'(?:stats?|statistics)\s+(.+?)(?:\s*$|[.!?])'
    ]
    
    # Try to extract the creature name
    creature_name = None
    for pattern in creature_patterns:
        match = re.search(pattern, query_lower)
        if match:
            creature_name = match.group(1).strip()
            break
    
    # Auto-detect intent based on query patterns
    suggested_types = []
    
    if any(word in query_lower for word in ['stats', 'statistics', 'stat block', 'ac ', 'hp ', 'hit points']):
        suggested_types.append('monster')
    
    if any(word in query_lower for word in ['spell', 'cantrip', 'magic', 'cast', 'level']):
        suggested_types.append('spell')
        
    if any(word in query_lower for word in ['table', 'roll', 'random', 'generator', 'd6', 'd20']):
        suggested_types.append('table')
        
    if any(word in query_lower for word in ['rule', 'mechanic', 'how to', 'procedure']):
        suggested_types.append('rule')
        
    if any(word in query_lower for word in ['weapon', 'armor', 'equipment', 'gear', 'damage']):
        suggested_types.append('equipment')
    
    # Use creature name if found, otherwise use original query
    processed_query = creature_name if creature_name else query_text
    
    return processed_query, suggested_types

def cmd_rag_query(args):
    """Handle RAG query command"""
    # Preprocess the query
    processed_query, auto_types = _preprocess_query(args.query)
    
    # Parse chunk type filters
    chunk_types = None
    if hasattr(args, 'types') and args.types:
        chunk_types = [t.strip() for t in args.types.split(',')]
        print(f"ğŸ” Searching knowledge base for: {args.query} (filtering by types: {chunk_types})")
    elif auto_types:
        # Auto-suggest types if not specified
        chunk_types = auto_types
        print(f"ğŸ” Searching knowledge base for: {args.query}")
        print(f"ğŸ’¡ Auto-detected content types: {auto_types}")
        
        # Use the processed query if we extracted a creature name
        if processed_query != args.query:
            print(f"ğŸ¯ Refined search term: '{processed_query}'")
    else:
        print(f"ğŸ” Searching knowledge base for: {args.query}")
    
    try:
        with Session(engine) as sess:
            # Use processed query for better results
            search_term = processed_query if processed_query != args.query else args.query
            chunks = query(sess, search_term, k=args.k, chunk_types=chunk_types)
            
        if not chunks:
            print("âŒ No results found")
            return
        
        print(f"ğŸ“š Found {len(chunks)} relevant chunks:")
        print("=" * 50)
        
        for i, chunk in enumerate(chunks, 1):
            # Document info is already loaded through relationship
            doc = chunk.document
            doc_title = doc.title if doc else "Unknown"
            doc_type = doc.doctype if doc else "unknown"
            chunk_type = chunk.chunk_type or "unclassified"
            
            print(f"\n{i}. Document: {doc_title}")
            print(f"   Doc Type: {doc_type} | Chunk Type: {chunk_type}")
            if chunk.section:
                print(f"   Section: {chunk.section}")
            if chunk.page:
                print(f"   Page: {chunk.page}")
            
            # Show first 300 chars of content
            preview = chunk.text[:300].replace('\n', ' ')
            if len(chunk.text) > 300:
                preview += "..."
            print(f"   Content: {preview}")
        
        print("=" * 50)
        
    except Exception as e:
        print(f"âŒ Error querying knowledge base: {e}")

def main():
    parser = argparse.ArgumentParser(
        description="Shadowdark GM Assistant CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s chat                                    # Start interactive chat mode
  %(prog)s chat "What are troll stats?"           # Single question mode
  %(prog)s session summarize transcript.txt
  %(prog)s session summarize audio.wav --campaign 1 --use-rag --out notion
  %(prog)s rag ingest shadowdark_rules.pdf --doctype rule
  %(prog)s rag query "shambling mound" --types monster
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Chat interface
    chat_parser = subparsers.add_parser('chat', help='Interactive chat with GM Assistant')
    chat_parser.add_argument('--reset', action='store_true', help='Reset conversation history')
    chat_parser.add_argument('message', nargs='*', help='Single message (optional, triggers interactive mode if not provided)')
    
    # Session commands
    session_parser = subparsers.add_parser('session', help='Session management')
    session_subparsers = session_parser.add_subparsers(dest='session_cmd')
    
    # Session summarize
    summarize_parser = session_subparsers.add_parser('summarize', help='Generate session notes from transcript or audio')
    summarize_parser.add_argument('input', help='Input file (transcript, audio, notes, etc.)')
    summarize_parser.add_argument('--out', default='stdout', 
                                  help='Output destination: stdout, notion, or filename (default: stdout)')
    summarize_parser.add_argument('--campaign', type=int, help='Campaign ID for database storage')
    summarize_parser.add_argument('--use-rag', action='store_true', 
                                  help='Use RAG to include relevant context from knowledge base')
    summarize_parser.add_argument('--save-to-db', action='store_true',
                                  help='Save session data to database')
    summarize_parser.add_argument('--play-group', choices=['Post 161', 'Online'], 
                                  default='Online', help='Play group for Notion (default: Online)')
    summarize_parser.add_argument('--fast', action='store_true',
                                  help='Fast mode: skip speaker diarization for faster processing')
    
    # Audio processing commands
    audio_parser = subparsers.add_parser('audio', help='Audio processing utilities')
    audio_subparsers = audio_parser.add_subparsers(dest='audio_cmd')
    
    # Audio split
    split_parser = audio_subparsers.add_parser('split', help='Split large audio files into smaller segments')
    split_parser.add_argument('input', help='Input audio file to split')
    split_parser.add_argument('--output-dir', help='Directory to save segments (default: same as input)')
    
    # Audio transcribe (generate transcript without session notes)
    transcribe_parser = audio_subparsers.add_parser('transcribe', help='Generate diarized transcript for manual review')
    transcribe_parser.add_argument('input', help='Input audio file')
    transcribe_parser.add_argument('--out', help='Output transcript file (default: auto-generated)')
    transcribe_parser.add_argument('--min-speakers', type=int, help='Minimum number of speakers')
    transcribe_parser.add_argument('--max-speakers', type=int, help='Maximum number of speakers')
    
    # Transcript utilities
    transcript_parser = subparsers.add_parser('transcript', help='Transcript processing utilities')
    transcript_subparsers = transcript_parser.add_subparsers(dest='transcript_cmd')
    
    # Transcript merge
    merge_parser = transcript_subparsers.add_parser('merge', help='Merge multiple segment transcripts')
    merge_parser.add_argument('output', help='Output file for merged transcript')
    merge_parser.add_argument('transcripts', nargs='+', help='Transcript files to merge')
    
    # RAG commands
    rag_parser = subparsers.add_parser('rag', help='Knowledge base management')
    rag_subparsers = rag_parser.add_subparsers(dest='rag_cmd')
    
    # RAG ingest
    ingest_parser = rag_subparsers.add_parser('ingest', help='Add documents to knowledge base')
    ingest_parser.add_argument('file', help='File to ingest (PDF, Markdown, or text)')
    ingest_parser.add_argument('--title', help='Document title (defaults to filename)')
    ingest_parser.add_argument('--doctype', choices=['rule', 'note', 'transcript', 'monster', 'spell', 'equipment', 'setting', 'supplement', 'table', 'adventure', 'lore', 'reference', 'other'],
                               help='Document type')
    
    # RAG batch ingest
    batch_ingest_parser = rag_subparsers.add_parser('ingest-batch', help='Add multiple documents from directory')
    batch_ingest_parser.add_argument('directory', help='Directory containing files to ingest')
    batch_ingest_parser.add_argument('--doctype', choices=['rule', 'note', 'transcript', 'monster', 'spell', 'equipment', 'setting', 'supplement', 'table', 'adventure', 'lore', 'reference', 'other'],
                                    help='Document type for all files (optional, will auto-detect if not provided)')
    batch_ingest_parser.add_argument('--recursive', '-r', action='store_true', help='Process subdirectories recursively')
    batch_ingest_parser.add_argument('--extensions', default='pdf,md,txt', help='File extensions to process (comma-separated, default: pdf,md,txt)')
    
    # RAG query
    query_parser = rag_subparsers.add_parser('query', help='Search knowledge base')
    query_parser.add_argument('query', help='Search query')
    query_parser.add_argument('--k', type=int, default=5, help='Number of results to return')
    query_parser.add_argument('--types', help='Filter by chunk types (comma-separated: monster,spell,rule,table,equipment)')
    query_parser.add_argument('--doctype', help='Filter by document type (for compatibility)')
    
    # RAG list
    list_parser = rag_subparsers.add_parser('list', help='List documents in knowledge base')
    list_parser.add_argument('--doctype', help='Filter by document type')
    
    # RAG remove  
    remove_parser = rag_subparsers.add_parser('remove', help='Remove document from knowledge base')
    remove_parser.add_argument('doc_id', type=int, help='Document ID to remove')
    
def cmd_audio_split(args):
    """Handle audio split command"""
    try:
        from core.agents.audio_splitter import split_audio_file
        
        print(f"ğŸ”ª Splitting audio file: {args.input}")
        segments = split_audio_file(args.input, args.output_dir)
        
        print(f"\nâœ… Successfully split into {len(segments)} segments:")
        for i, segment in enumerate(segments, 1):
            size_mb = segment.stat().st_size / (1024 * 1024)
            print(f"   {i}. {segment.name} ({size_mb:.1f}MB)")
        
        print(f"\nğŸ“‹ Next steps:")
        print(f"   1. Process each segment: ./gm audio transcribe segment_001.m4a")
        print(f"   2. Merge transcripts: ./gm transcript merge merged.md segment_*_transcript.md")
        print(f"   3. Review and edit: vim merged.md") 
        print(f"   4. Generate notes: ./gm session summarize merged.md")
        
    except Exception as e:
        print(f"âŒ Error splitting audio: {e}")

def cmd_audio_transcribe(args):
    """Handle audio transcribe command"""
    try:
        from core.agents.transcript_generator import generate_transcript
        
        huggingface_token = os.getenv("HUGGINGFACE_TOKEN")
        openai_api_key = os.getenv("OPENAI_API_KEY")
        
        print(f"ğŸ™ï¸  Generating transcript from: {args.input}")
        
        transcript_path = generate_transcript(
            audio_path=args.input,
            output_path=args.out,
            huggingface_token=huggingface_token,
            openai_api_key=openai_api_key,
            min_speakers=args.min_speakers,
            max_speakers=args.max_speakers
        )
        
        print(f"\nâœ… Transcript generated: {transcript_path}")
        print(f"\nğŸ“ Please review and edit the transcript, then:")
        print(f"   ./gm session summarize {transcript_path}")
        
    except Exception as e:
        print(f"âŒ Error generating transcript: {e}")
        if "gated repo" in str(e).lower() or "access" in str(e).lower():
            print("\nğŸ’¡ To enable audio processing:")
            print("1. Visit: https://huggingface.co/pyannote/speaker-diarization-community-1")
            print("2. Click 'Agree and access repository'")
            print("3. Create token: https://huggingface.co/settings/tokens")
            print("4. Add HUGGINGFACE_TOKEN to your .env file")

def cmd_transcript_merge(args):
    """Handle transcript merge command"""
    try:
        from core.agents.transcript_merger import merge_transcript_files
        
        print(f"ğŸ”— Merging {len(args.transcripts)} transcript files...")
        
        merged_path = merge_transcript_files(args.transcripts, args.output)
        
        print(f"\nâœ… Merged transcript created: {merged_path}")
        print(f"\nğŸ“ Please review the merged transcript, then:")
        print(f"   ./gm session summarize {merged_path}")
        
    except Exception as e:
        print(f"âŒ Error merging transcripts: {e}")

    args = parser.parse_args()
    
    if args.command == 'chat':
        cmd_chat(args)
    elif args.command == 'session':
        if args.session_cmd == 'summarize':
            cmd_session_summarize(args)
        else:
            session_parser.print_help()
    elif args.command == 'audio':
        if args.audio_cmd == 'split':
            cmd_audio_split(args)
        elif args.audio_cmd == 'transcribe':
            cmd_audio_transcribe(args)
        else:
            audio_parser.print_help()
    elif args.command == 'transcript':
        if args.transcript_cmd == 'merge':
            cmd_transcript_merge(args)
        else:
            transcript_parser.print_help()
    elif args.command == 'rag':
        if args.rag_cmd == 'ingest':
            cmd_rag_ingest(args)
        elif args.rag_cmd == 'ingest-batch':
            cmd_rag_ingest_batch(args)
        elif args.rag_cmd == 'query':
            cmd_rag_query(args)
        else:
            rag_parser.print_help()
    else:
        parser.print_help()

if __name__ == '__main__':
    main()